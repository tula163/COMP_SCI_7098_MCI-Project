{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04b063f5-cc8b-4795-bc40-9d683e778ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.metrics import precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3989f-4323-4a61-8eed-d0ab7da937b0",
   "metadata": {},
   "source": [
    "## 1. Data preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a6ad0c-bf94-4c58-8881-6308cc71d786",
   "metadata": {},
   "source": [
    "### Read the data file and print the first 5 lines in the initial data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de767de0-1fc5-4039-8e6e-2c8a2251f7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MARN       Full_name  Experience_years         Charge  Visa type  \\\n",
      "0  1800328     Kumar Rahul                 7  201 – 500 AUD        491   \n",
      "1  1799100  Ramandeep Kaur                 8       500+ AUD        838   \n",
      "2  1799035   Jaspreet Kaur                 8  201 – 500 AUD        151   \n",
      "3  2318090    Balwant Kaur                 2   101– 200 AUD        175   \n",
      "4  1570947          Nahida                10  201 – 500 AUD        423   \n",
      "\n",
      "  Booking preference Location Success rate    Language Employment Type  \\\n",
      "0             Online       SA         >81%  Vietnamese       Organized   \n",
      "1             Online      QLD        < 30%    Japanese     Independent   \n",
      "2               Both      VIC         >81%     Serbian     Independent   \n",
      "3           Inperson      VIC      31%-50%     Tagalog       Organized   \n",
      "4               Both       SA        < 30%    Romanian       Organized   \n",
      "\n",
      "   Google rating Availability  \n",
      "0            4.9   4- 6 month  \n",
      "1            2.9   4- 6 month  \n",
      "2            4.1  2 - 3 month  \n",
      "3            3.1   4- 6 month  \n",
      "4            4.0  Immediately  \n"
     ]
    }
   ],
   "source": [
    "## read the datafile and print the inital datafile\n",
    "df = pd.read_csv(\"requirements_data_5.6.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef90c6-4fc5-426b-84d8-d5e78e848519",
   "metadata": {},
   "source": [
    "### Print the columns' name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1be32b3-65ce-4fb2-9acd-e23b813deb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MARN', 'Full_name', 'Experience_years', 'Charge', 'Visa type',\n",
      "       'Booking preference', 'Location', 'Success rate', 'Language',\n",
      "       'Employment Type', 'Google rating', 'Availability'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b6db97-b862-4de1-a0d4-30b94a8b70bc",
   "metadata": {},
   "source": [
    "### Print the information of the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d7938c-b25b-4030-86f0-e5424630e0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4534 entries, 0 to 4533\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   MARN                4534 non-null   int64  \n",
      " 1   Full_name           4534 non-null   object \n",
      " 2   Experience_years    4534 non-null   int64  \n",
      " 3   Charge              4534 non-null   object \n",
      " 4   Visa type           4534 non-null   int64  \n",
      " 5   Booking preference  4534 non-null   object \n",
      " 6   Location            4534 non-null   object \n",
      " 7   Success rate        4534 non-null   object \n",
      " 8   Language            4534 non-null   object \n",
      " 9   Employment Type     4534 non-null   object \n",
      " 10  Google rating       4534 non-null   float64\n",
      " 11  Availability        4534 non-null   object \n",
      "dtypes: float64(1), int64(3), object(8)\n",
      "memory usage: 425.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb13f16-396e-49ce-aedb-4125fc941456",
   "metadata": {},
   "source": [
    "### Print the number of rows and columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a3ad10c-3d18-4320-b1a1-e01b2dab34f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4534, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c0e174-3ab7-482c-a91b-baa176ec10fe",
   "metadata": {},
   "source": [
    "## 2. Data preprogress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd0581-1d13-4774-9454-ee5a9d3fc02f",
   "metadata": {},
   "source": [
    "### Correct the data type of the data column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19b1f821-c29e-4851-ab62-3bacf9763448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4534 entries, 0 to 4533\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   MARN                4534 non-null   object \n",
      " 1   Full_name           4534 non-null   object \n",
      " 2   Experience_years    4534 non-null   int64  \n",
      " 3   Charge              4534 non-null   object \n",
      " 4   Visa type           4534 non-null   object \n",
      " 5   Booking preference  4534 non-null   object \n",
      " 6   Location            4534 non-null   object \n",
      " 7   Success rate        4534 non-null   object \n",
      " 8   Language            4534 non-null   object \n",
      " 9   Employment Type     4534 non-null   object \n",
      " 10  Google rating       4534 non-null   float64\n",
      " 11  Availability        4534 non-null   object \n",
      "dtypes: float64(1), int64(1), object(10)\n",
      "memory usage: 425.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## MARN is the unique id for agents, and Visa type is not a numerical data, so change them into string type\n",
    "df[\"MARN\"] = df[\"MARN\"].astype(str)\n",
    "df[\"Visa type\"] = df[\"Visa type\"].astype(str)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040f767f-da87-44e2-ba1c-59f9f3b433c6",
   "metadata": {},
   "source": [
    "### Select the attributes in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7c8aa7ba-b587-4344-bc90-ae1fc00f98d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# select the attributes columns\n",
    "attribute_columns = [\n",
    "    \"Experience_years\",\n",
    "    \"Charge\",\n",
    "    \"Visa type\",\n",
    "    \"Booking preference\",\n",
    "    \"Location\",\n",
    "    \"Success rate\",\n",
    "    \"Language\",\n",
    "    \"Employment Type\",\n",
    "    \"Google rating\",\n",
    "    \"Availability\"\n",
    "]\n",
    "# identify the numerical data and categorical data\n",
    "numerical_cols = [\"Experience_years\", \"Google rating\"]\n",
    "categorical_cols = [col for col in attribute_columns if col not in numerical_cols]\n",
    "\n",
    "# create a preprocessor to transform data into vectors\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),    #transform the numerical attributes to have similar weight\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)    #transform the categorical attributes into numerical vector\n",
    "    ]\n",
    ")\n",
    "\n",
    "X = preprocessor.fit_transform(df[attribute_columns])\n",
    "# print(X.shape)\n",
    "# print(type(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744121c2-0c3f-4f09-96b4-78196d511ae2",
   "metadata": {},
   "source": [
    "## 3. Train the KNN-CF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e9150b-9268-423d-b982-42c1354a4758",
   "metadata": {},
   "source": [
    "### Initialise the KNN model, use a sample user input to test the output, including the top 3 recommendations and match scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fe14199-cf4b-4bee-8b17-b4284c603c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 recommendations：\n",
      "1. Kumar Rahul (MARN: 1800328) → match score: 100.0%\n",
      "2. Richard Hyosung Lee (MARN: 1384647) → match score: 82.6%\n",
      "3. Yi Luo (MARN: 1802013) → match score: 78.5%\n"
     ]
    }
   ],
   "source": [
    "# initialise the KNN model\n",
    "knn = NearestNeighbors(n_neighbors=3, metric='cosine') \n",
    "knn.fit(X)\n",
    "\n",
    "# initial test input\n",
    "user_input = {\n",
    "    \"Experience_years\": 7,\n",
    "    \"Charge\": \"201 – 500 AUD\",\n",
    "    \"Visa type\": \"491\",\n",
    "    \"Booking preference\": \"Online\",\n",
    "    \"Location\": \"SA\",\n",
    "    \"Success rate\": \">81%\",\n",
    "    \"Language\": \"Vietnamese\",\n",
    "    \"Employment Type\": \"Organized\",\n",
    "    \"Google rating\": 4.9,\n",
    "    \"Availability\": \"4- 6 month\"\n",
    "}\n",
    "user_df = pd.DataFrame([user_input])\n",
    "user_encoded = preprocessor.transform(user_df)\n",
    "distances, indices = knn.kneighbors(user_encoded, n_neighbors=3)\n",
    "\n",
    "print(\"Top 3 recommendations：\")\n",
    "for idx, (i, dist) in enumerate(zip(indices[0], distances[0])):\n",
    "    name = df.iloc[i][\"Full_name\"]\n",
    "    marn = df.iloc[i][\"MARN\"]\n",
    "    # show the match scores（example：1 / (1 + distance)）\n",
    "    percent_score = (1 / (1 + dist)) * 100\n",
    "    print(f\"{idx + 1}. {name} (MARN: {marn}) → match score: {percent_score:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffcbc6a-efea-4c8a-a658-7ca926bdda8b",
   "metadata": {},
   "source": [
    "### Use the non-return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b15e84e-a979-4baf-bd82-e56b936463a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split:\n",
      "Recall: 0.0000\n",
      "Accuracy: 0.0000\n",
      "\n",
      "Training with 80% / 20% split:\n",
      "Recall: 0.0000\n",
      "Accuracy: 0.0000\n",
      "\n",
      "Training with 90% / 10% split:\n",
      "Recall: 0.0000\n",
      "Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# if not resample train\n",
    "for train_size, test_size in splits:\n",
    "    print(f\"\\nTraining with {int(train_size * 100)}% / {int(test_size * 100)}% split:\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, test_size=test_size, random_state=42)\n",
    "    knn = NearestNeighbors(n_neighbors=3, metric='cosine')\n",
    "    \n",
    "    knn.fit(X_train)\n",
    "    \n",
    "    distances, indices = knn.kneighbors(X_test)\n",
    "    \n",
    "    y_pred = np.array([y_train.iloc[indices[i]].values[0] for i in range(len(indices))])\n",
    "\n",
    "    recall = recall_score(y_test, y_pred, average='micro')  # micro 平均方式考虑所有类别\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab31b5-0e7d-4c4f-875b-12a327335675",
   "metadata": {},
   "source": [
    "Because all the labels in our dataset show up only once, the output is not good. We need to try the resample method for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77b6122-6e83-49b4-b8cf-0be1bf54a015",
   "metadata": {},
   "source": [
    "### Define a function to calculate the accuracy, recall, precision and F1-score for the resample method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c39b4a86-4464-45f7-beb6-f839c1fa8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_cal(splits, n_total, feature_X, label_Y):\n",
    "    for train_size, test_size in splits:\n",
    "        print(f\"\\nTraining with {int(train_size * 100)}% / {int(test_size * 100)}% split:\")\n",
    "        \n",
    "        n_train = int(train_size * n_total)\n",
    "        n_test = int(test_size * n_total)\n",
    "        \n",
    "        X_train, y_train = resample(feature_X, label_Y, replace=True, n_samples=n_train)\n",
    "        X_test, y_test = resample(feature_X, label_Y, replace=True, n_samples=n_test)\n",
    "        knn = NearestNeighbors(n_neighbors=3, metric='cosine')\n",
    "        knn.fit(X_train)\n",
    "        distances, indices = knn.kneighbors(X_test)\n",
    "    \n",
    "        # generate top 3 recommendations\n",
    "        top_k_preds = [y_train.iloc[indices[i]].values for i in range(len(indices))]\n",
    "    \n",
    "        # Recall@3\n",
    "        hits = [y_test.iloc[i] in top_k_preds[i] for i in range(len(y_test))]\n",
    "        recall_at_3 = sum(hits) / len(hits)\n",
    "    \n",
    "        # Precision@3\n",
    "        correct_preds = [np.sum(top_k_preds[i] == y_test.iloc[i]) for i in range(len(y_test))]\n",
    "        precision_at_3 = sum(correct_preds) / (len(y_test) * 3)\n",
    "    \n",
    "        # F1-score@3\n",
    "        if recall_at_3 + precision_at_3 > 0:\n",
    "            f1_at_3 = 2 * precision_at_3 * recall_at_3 / (precision_at_3 + recall_at_3)\n",
    "        else:\n",
    "            f1_at_3 = 0.0\n",
    "            \n",
    "        accuracy_at_3 = sum(correct_preds) / (len(y_test) * 3)\n",
    "    \n",
    "        print(f\"Recall@3:    {recall_at_3:.4f}\")\n",
    "        print(f\"Precision@3: {precision_at_3:.4f}\")\n",
    "        print(f\"F1-score@3:  {f1_at_3:.4f}\")\n",
    "        print(f\"Accuracy@3:  {accuracy_at_3:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0712ca3a-54af-496d-a44e-3943e4f87215",
   "metadata": {},
   "source": [
    "#### The original dataframe size: 4533; split the dataset into the training sets and testing sets with 70% and 30%, 80% and 20%, 90% and 10%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "73e4b5b1-e93a-4bb9-bd89-d89c58fe6673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split:\n",
      "Recall@3:    0.5125\n",
      "Precision@3: 0.2407\n",
      "F1-score@3:  0.3275\n",
      "Accuracy@3:  0.2407\n",
      "\n",
      "Training with 80% / 20% split:\n",
      "Recall@3:    0.5508\n",
      "Precision@3: 0.2616\n",
      "F1-score@3:  0.3547\n",
      "Accuracy@3:  0.2616\n",
      "\n",
      "Training with 90% / 10% split:\n",
      "Recall@3:    0.5982\n",
      "Precision@3: 0.2995\n",
      "F1-score@3:  0.3991\n",
      "Accuracy@3:  0.2995\n"
     ]
    }
   ],
   "source": [
    "# resample methods to calculate metrics\n",
    "# split the training set and testing set\n",
    "y = df['MARN']\n",
    "splits = [(0.7, 0.3), (0.8, 0.2), (0.9, 0.1)]\n",
    "n_total = X.shape[0]\n",
    "resample_cal(splits, n_total, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c35c42-ed85-433a-ba72-be3fdbbdcaef",
   "metadata": {},
   "source": [
    "### Try multiple sampling to generate a larger training set for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6b120655-ab51-4e14-aab5-89de5238f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul_resample_cal(splits, n_total, feature_X, label_Y, n_repeats):\n",
    "    for train_size, test_size in splits:\n",
    "        print(f\"\\nTraining with {int(train_size*100)}% / {int(test_size*100)}% split with repeat {n_repeats}:\")\n",
    "    \n",
    "        n_train = int(train_size * n_total)\n",
    "        n_test = int(test_size * n_total)\n",
    "    \n",
    "        X_train_all = []\n",
    "        y_train_all = []\n",
    "    \n",
    "        for repeat in range(n_repeats):\n",
    "            X_tmp, y_tmp = resample(feature_X, label_Y, replace=True, n_samples=n_train, random_state=repeat * 10)\n",
    "            X_train_all.append(X_tmp)\n",
    "            y_train_all.append(y_tmp)\n",
    "    \n",
    "        X_train_combined = vstack(X_train_all)\n",
    "        y_train_combined = pd.concat(y_train_all).reset_index(drop=True)\n",
    "    \n",
    "        X_test, y_test = resample(feature_X, label_Y, replace=True, n_samples=n_test, random_state=100)\n",
    "    \n",
    "        knn = NearestNeighbors(n_neighbors=3, metric='cosine')\n",
    "        knn.fit(X_train_combined)\n",
    "    \n",
    "        distances, indices = knn.kneighbors(X_test)\n",
    "        top_k_preds = [y_train_combined.iloc[indices[i]].values for i in range(len(indices))]\n",
    "    \n",
    "        # Recall@3\n",
    "        hits = [y_test.iloc[i] in top_k_preds[i] for i in range(len(y_test))]\n",
    "        recall_at_3 = sum(hits) / len(hits)\n",
    "    \n",
    "        # Precision@3\n",
    "        correct_preds = [np.sum(top_k_preds[i] == y_test.iloc[i]) for i in range(len(y_test))]\n",
    "        precision_at_3 = sum(correct_preds) / (len(y_test) * 3)\n",
    "    \n",
    "        # F1-score@3\n",
    "        if recall_at_3 + precision_at_3 > 0:\n",
    "            f1_at_3 = 2 * precision_at_3 * recall_at_3 / (precision_at_3 + recall_at_3)\n",
    "        else:\n",
    "            f1_at_3 = 0.0\n",
    "            \n",
    "        accuracy_at_3 = sum(correct_preds) / (len(y_test) * 3)\n",
    "\n",
    "        print(f\"Accuracy@3:  {accuracy_at_3:.4f}\")\n",
    "        print(f\"Precision@3: {precision_at_3:.4f}\")\n",
    "        print(f\"Recall@3:    {recall_at_3:.4f}\")\n",
    "        print(f\"F1-score@3:  {f1_at_3:.4f}\")\n",
    "        \n",
    "    #return recall_at_3, precision_at_3, f1_at_3, accuracy_at_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c385fdcf-77c5-4d63-ba83-ad36f63e2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split with repeat 1:\n",
      "Accuracy@3:  0.2289\n",
      "Precision@3: 0.2289\n",
      "Recall@3:    0.4934\n",
      "F1-score@3:  0.3127\n",
      "\n",
      "Training with 80% / 20% split with repeat 1:\n",
      "Accuracy@3:  0.2535\n",
      "Precision@3: 0.2535\n",
      "Recall@3:    0.5353\n",
      "F1-score@3:  0.3441\n",
      "\n",
      "Training with 90% / 10% split with repeat 1:\n",
      "Accuracy@3:  0.2752\n",
      "Precision@3: 0.2752\n",
      "Recall@3:    0.5740\n",
      "F1-score@3:  0.3720\n"
     ]
    }
   ],
   "source": [
    "# resample methods to calculate metrics\n",
    "# Split the training set and testing set\n",
    "n_repeats = 1\n",
    "mul_resample_cal(splits, n_total, X, y, n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "60e2ffa0-74d0-4d2d-87e5-509cc0f4ac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split with repeat 2:\n",
      "Accuracy@3:  0.4414\n",
      "Precision@3: 0.4414\n",
      "Recall@3:    0.7331\n",
      "F1-score@3:  0.5510\n",
      "\n",
      "Training with 80% / 20% split with repeat 2:\n",
      "Accuracy@3:  0.4989\n",
      "Precision@3: 0.4989\n",
      "Recall@3:    0.7792\n",
      "F1-score@3:  0.6083\n",
      "\n",
      "Training with 90% / 10% split with repeat 2:\n",
      "Accuracy@3:  0.5563\n",
      "Precision@3: 0.5563\n",
      "Recall@3:    0.8234\n",
      "F1-score@3:  0.6640\n"
     ]
    }
   ],
   "source": [
    "# resample methods to calculate metrics\n",
    "# Split the training set and testing set\n",
    "n_repeats = 2\n",
    "mul_resample_cal(splits, n_total, X, y, n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c77b9095-b9ff-4372-a3b5-faa5898ebb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split with repeat 3:\n",
      "Accuracy@3:  0.6135\n",
      "Precision@3: 0.6135\n",
      "Recall@3:    0.8824\n",
      "F1-score@3:  0.7238\n",
      "\n",
      "Training with 80% / 20% split with repeat 3:\n",
      "Accuracy@3:  0.6733\n",
      "Precision@3: 0.6733\n",
      "Recall@3:    0.9106\n",
      "F1-score@3:  0.7742\n",
      "\n",
      "Training with 90% / 10% split with repeat 3:\n",
      "Accuracy@3:  0.7344\n",
      "Precision@3: 0.7344\n",
      "Recall@3:    0.9470\n",
      "F1-score@3:  0.8272\n"
     ]
    }
   ],
   "source": [
    "n_repeats = 3\n",
    "mul_resample_cal(splits, n_total, X, y, n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cbb0a741-c7e7-4660-bbdf-11220cb62a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split with repeat 4:\n",
      "Accuracy@3:  0.7439\n",
      "Precision@3: 0.7439\n",
      "Recall@3:    0.9382\n",
      "F1-score@3:  0.8298\n",
      "\n",
      "Training with 80% / 20% split with repeat 4:\n",
      "Accuracy@3:  0.7995\n",
      "Precision@3: 0.7995\n",
      "Recall@3:    0.9614\n",
      "F1-score@3:  0.8730\n",
      "\n",
      "Training with 90% / 10% split with repeat 4:\n",
      "Accuracy@3:  0.8609\n",
      "Precision@3: 0.8609\n",
      "Recall@3:    0.9845\n",
      "F1-score@3:  0.9186\n"
     ]
    }
   ],
   "source": [
    "n_repeats = 4\n",
    "mul_resample_cal(splits, n_total, X, y, n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3a7c2d8f-ff48-4242-aac4-9f08fb57ac6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split with repeat 5:\n",
      "Accuracy@3:  0.8353\n",
      "Precision@3: 0.8353\n",
      "Recall@3:    0.9721\n",
      "F1-score@3:  0.8985\n",
      "\n",
      "Training with 80% / 20% split with repeat 5:\n",
      "Accuracy@3:  0.8837\n",
      "Precision@3: 0.8837\n",
      "Recall@3:    0.9890\n",
      "F1-score@3:  0.9334\n",
      "\n",
      "Training with 90% / 10% split with repeat 5:\n",
      "Accuracy@3:  0.9249\n",
      "Precision@3: 0.9249\n",
      "Recall@3:    0.9978\n",
      "F1-score@3:  0.9600\n"
     ]
    }
   ],
   "source": [
    "n_repeats = 5\n",
    "mul_resample_cal(splits, n_total, X, y, n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f3dd67a8-fc94-4472-be0b-c6918c14ee92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split with repeat 6:\n",
      "Accuracy@3:  0.8973\n",
      "Precision@3: 0.8973\n",
      "Recall@3:    0.9838\n",
      "F1-score@3:  0.9386\n",
      "\n",
      "Training with 80% / 20% split with repeat 6:\n",
      "Accuracy@3:  0.9371\n",
      "Precision@3: 0.9371\n",
      "Recall@3:    0.9945\n",
      "F1-score@3:  0.9649\n",
      "\n",
      "Training with 90% / 10% split with repeat 6:\n",
      "Accuracy@3:  0.9662\n",
      "Precision@3: 0.9662\n",
      "Recall@3:    1.0000\n",
      "F1-score@3:  0.9828\n"
     ]
    }
   ],
   "source": [
    "n_repeats = 6\n",
    "mul_resample_cal(splits, n_total, X, y, n_repeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54078259-0585-4ca8-844b-01cde76d1e8d",
   "metadata": {},
   "source": [
    "After the experiment, it was found that repeating 5 times yielded the best results, but repeating 6 times would result in overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02dcdd-80a3-4d9b-86c3-4aee828b1d70",
   "metadata": {},
   "source": [
    "### Change the weights of attributes for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff610c1-f863-4c69-9a8e-26a3fd27481d",
   "metadata": {},
   "source": [
    "#### define a function to set the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1ae5f649-e33e-4b85-9726-1bf1b7b71fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weights(base_weights, preprocessor):\n",
    "    # set the weights to the onecode matrix\n",
    "    one_hot_encode = preprocessor.named_transformers_['cat']\n",
    "    cat_dims = [len(cats) for cats in one_hot_encode.categories_]\n",
    "    num_dims = len(numerical_cols)\n",
    "    \n",
    "    weights_expanded = []\n",
    "    \n",
    "    for i in range(num_dims):\n",
    "        weights_expanded.append(np.full(1, base_weights[i]))\n",
    "    \n",
    "    for i, dim in enumerate(cat_dims):\n",
    "        weights_expanded.append(np.full(dim, base_weights[num_dims + i]))\n",
    "    \n",
    "    full_weights = np.concatenate(weights_expanded)\n",
    "    X_weighted = X * full_weights\n",
    "    X_weighted = X_weighted.reshape(-1, 1)\n",
    "    # print(X_weighted_1.shape)\n",
    "    return X_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f65b07e3-8684-4963-8c25-6cb80686c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul_set_weights(base_weights, preprocessor, X):\n",
    "    # X 是原始稀疏矩阵，例如 TF-IDF 矩阵，或经过 ColumnTransformer 后的输出\n",
    "    one_hot_encode = preprocessor.named_transformers_['cat']\n",
    "    cat_dims = [len(cats) for cats in one_hot_encode.categories_]\n",
    "    num_dims = len(numerical_cols)\n",
    "\n",
    "    weights_expanded = []\n",
    "\n",
    "    for i in range(num_dims):\n",
    "        weights_expanded.append(np.full(1, base_weights[i]))\n",
    "\n",
    "    for i, dim in enumerate(cat_dims):\n",
    "        weights_expanded.append(np.full(dim, base_weights[num_dims + i]))\n",
    "\n",
    "    full_weights = np.concatenate(weights_expanded)\n",
    "\n",
    "    # 确保 full_weights 是 1D array，长度 == 特征维度\n",
    "    if X.shape[1] != len(full_weights):\n",
    "        raise ValueError(f\"Shape mismatch: X has {X.shape[1]} features, but weights have {len(full_weights)} values\")\n",
    "\n",
    "    # 关键点：使用 sparse matrix 的乘法，按列缩放\n",
    "    from scipy.sparse import diags\n",
    "    W = diags(full_weights)  # 创建一个对角矩阵\n",
    "    mul_X_weighted = X @ W       # 右乘，对每列应用权重\n",
    "\n",
    "    return mul_X_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b26f10-64b9-4378-b7f1-5a298223f671",
   "metadata": {},
   "source": [
    "#### 1. Test the weight set 1: feature_weights_1 = weights = {\r\n",
    "\"Language\": 0.25, \r\n",
    "\"Google rating\": 0.20, \r\n",
    "\"Success rate\": 0.15, \r\n",
    "\"Charge\": 0.10,\r\n",
    "\"Visa type\": 0.10, \r\n",
    "\"Experience_years\": 0.05, \r\n",
    "\"Booking preference\": 0.05,\r\n",
    "\"Location\": 0.03, \r\n",
    "\"Availability\": 0.03, \r\n",
    "\"Employment Type\": 0.04\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "afd0f05f-026b-4354-952e-1161b56627aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split:\n",
      "Recall@3:    0.0015\n",
      "Precision@3: 0.0005\n",
      "F1-score@3:  0.0007\n",
      "Accuracy@3:  0.0005\n",
      "\n",
      "Training with 80% / 20% split:\n",
      "Recall@3:    0.0011\n",
      "Precision@3: 0.0004\n",
      "F1-score@3:  0.0006\n",
      "Accuracy@3:  0.0004\n",
      "\n",
      "Training with 90% / 10% split:\n",
      "Recall@3:    0.0000\n",
      "Precision@3: 0.0000\n",
      "F1-score@3:  0.0000\n",
      "Accuracy@3:  0.0000\n"
     ]
    }
   ],
   "source": [
    "# weight set 1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse\n",
    "base_weights_1 = np.array([0.25, 0.20, 0.15, 0.10, 0.10, 0.05, 0.05, 0.03, 0.03, 0.04])\n",
    "X_weighted_1 = set_weights(base_weights_1, preprocessor)\n",
    "# print(X_weighted_1)\n",
    "resample_cal(splits, n_total, X_weighted_1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "74b546bb-439b-4c74-b4b7-f534f9fbed6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split with repeat 5:\n",
      "Accuracy@3:  0.8353\n",
      "Precision@3: 0.8353\n",
      "Recall@3:    0.9721\n",
      "F1-score@3:  0.8985\n",
      "\n",
      "Training with 80% / 20% split with repeat 5:\n",
      "Accuracy@3:  0.8837\n",
      "Precision@3: 0.8837\n",
      "Recall@3:    0.9890\n",
      "F1-score@3:  0.9334\n",
      "\n",
      "Training with 90% / 10% split with repeat 5:\n",
      "Accuracy@3:  0.9249\n",
      "Precision@3: 0.9249\n",
      "Recall@3:    0.9978\n",
      "F1-score@3:  0.9600\n"
     ]
    }
   ],
   "source": [
    "mul_X_weighted_1 = mul_set_weights(base_weights_1, preprocessor, X)\n",
    "mul_resample_cal(splits, n_total=X.shape[0], feature_X=mul_X_weighted_1, label_Y=y, n_repeats=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56e6918-aa37-473f-a24e-e39d6451c463",
   "metadata": {},
   "source": [
    "#### 2. Test the weight set 2: feature_weights_2 = {\r\n",
    "\"Language\": 0.15, \r\n",
    "\"Google rating\": 0.15, \r\n",
    "\"Success rate\": 0.20, \r\n",
    "\"Charge\": 0.25,\r\n",
    "\"Visa type\": 0.08, \r\n",
    "\"Experience_years\": 0.05, \r\n",
    "\"Booking preference\": 0.05,\r\n",
    "\"Location\": 0.02, \r\n",
    "\"Availability\": 0.02, \r\n",
    "\"Employment Type\": 0.03\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "97d87352-ad4b-4296-9ac3-67bb4bae9ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split:\n",
      "Recall@3:    0.0007\n",
      "Precision@3: 0.0002\n",
      "F1-score@3:  0.0004\n",
      "Accuracy@3:  0.0002\n",
      "\n",
      "Training with 80% / 20% split:\n",
      "Recall@3:    0.0000\n",
      "Precision@3: 0.0000\n",
      "F1-score@3:  0.0000\n",
      "Accuracy@3:  0.0000\n",
      "\n",
      "Training with 90% / 10% split:\n",
      "Recall@3:    0.0000\n",
      "Precision@3: 0.0000\n",
      "F1-score@3:  0.0000\n",
      "Accuracy@3:  0.0000\n"
     ]
    }
   ],
   "source": [
    "base_weights_2 = np.array([0.15, 0.15, 0.20, 0.25, 0.08, 0.05, 0.05, 0.02, 0.02, 0.03])\n",
    "X_weighted_2 = set_weights(base_weights_2, preprocessor)\n",
    "resample_cal(splits, n_total, X_weighted_2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2025bd8c-edd1-44c4-b10d-0b829358d5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split with repeat 5:\n",
      "Accuracy@3:  0.8353\n",
      "Precision@3: 0.8353\n",
      "Recall@3:    0.9721\n",
      "F1-score@3:  0.8985\n",
      "\n",
      "Training with 80% / 20% split with repeat 5:\n",
      "Accuracy@3:  0.8837\n",
      "Precision@3: 0.8837\n",
      "Recall@3:    0.9890\n",
      "F1-score@3:  0.9334\n",
      "\n",
      "Training with 90% / 10% split with repeat 5:\n",
      "Accuracy@3:  0.9249\n",
      "Precision@3: 0.9249\n",
      "Recall@3:    0.9978\n",
      "F1-score@3:  0.9600\n"
     ]
    }
   ],
   "source": [
    "mul_X_weighted_2 = mul_set_weights(base_weights_2, preprocessor, X)\n",
    "mul_resample_cal(splits, n_total=X.shape[0], feature_X=mul_X_weighted_2, label_Y=y, n_repeats=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35248709-6a0e-4eca-84f2-106bc55aa02b",
   "metadata": {},
   "source": [
    "#### 3. Test the weight set 3: feature_weights_3 = {\r",
    "\"Language\": 0.10, \r\n",
    "\"Google rating\": 0.15, \r\n",
    "\"Success rate\": 0.20, \r\n",
    "\"Charge\": 0.05,\r\n",
    "\"Visa type\": 0.10, \r\n",
    "\"Experience_years\": 0.05, \r\n",
    "\"Booking preference\": 0.05,\r\n",
    "\"Location\": 0.02, \r\n",
    "\"Availability\": 0.25, \r\n",
    "\"Employment Ty\n",
    "e\": 0.03ype\": 0.03\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "612976d0-d6c9-4307-9805-748b286e5fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split:\n",
      "Recall@3:    0.0007\n",
      "Precision@3: 0.0002\n",
      "F1-score@3:  0.0004\n",
      "Accuracy@3:  0.0002\n",
      "\n",
      "Training with 80% / 20% split:\n",
      "Recall@3:    0.0000\n",
      "Precision@3: 0.0000\n",
      "F1-score@3:  0.0000\n",
      "Accuracy@3:  0.0000\n",
      "\n",
      "Training with 90% / 10% split:\n",
      "Recall@3:    0.0000\n",
      "Precision@3: 0.0000\n",
      "F1-score@3:  0.0000\n",
      "Accuracy@3:  0.0000\n"
     ]
    }
   ],
   "source": [
    "base_weights_3 = np.array([0.10, 0.15, 0.20, 0.05, 0.10, 0.05, 0.05, 0.02, 0.25, 0.03])\n",
    "X_weighted_3 = set_weights(base_weights_3, preprocessor)\n",
    "resample_cal(splits, n_total, X_weighted_3, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "873bfa35-ea21-40f5-8f47-f202d0210d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split with repeat 5:\n",
      "Accuracy@3:  0.8353\n",
      "Precision@3: 0.8353\n",
      "Recall@3:    0.9721\n",
      "F1-score@3:  0.8985\n",
      "\n",
      "Training with 80% / 20% split with repeat 5:\n",
      "Accuracy@3:  0.8837\n",
      "Precision@3: 0.8837\n",
      "Recall@3:    0.9890\n",
      "F1-score@3:  0.9334\n",
      "\n",
      "Training with 90% / 10% split with repeat 5:\n",
      "Accuracy@3:  0.9249\n",
      "Precision@3: 0.9249\n",
      "Recall@3:    0.9978\n",
      "F1-score@3:  0.9600\n"
     ]
    }
   ],
   "source": [
    "mul_X_weighted_3 = mul_set_weights(base_weights_3, preprocessor, X)\n",
    "mul_resample_cal(splits, n_total=X.shape[0], feature_X=mul_X_weighted_3, label_Y=y, n_repeats=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee82f7fd-b2eb-4839-a970-c5a03015a74b",
   "metadata": {},
   "source": [
    "#### 4. Test the weight set 4: feature_weights_4 = {\n",
    "\"Language\": 0.15, \r\n",
    "\"Google rating\": 0.25, \r\n",
    "\"Success rate\": 0.30, \r\n",
    "\"Charge\": 0.05,\r\n",
    "\"Visa type\": 0.10, \r\n",
    "\"Experience_years\": 0.05, \r\n",
    "\"Booking preference\": 0.03,\r\n",
    "\"Location\": 0.02, \r\n",
    "\"Availability\": 0.02, \r\n",
    "\"Employment Ty\n",
    "}pe\": 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "24980c2a-83b3-4714-8150-7df21ae3f7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split:\n",
      "Recall@3:    0.0022\n",
      "Precision@3: 0.0007\n",
      "F1-score@3:  0.0011\n",
      "Accuracy@3:  0.0007\n",
      "\n",
      "Training with 80% / 20% split:\n",
      "Recall@3:    0.0011\n",
      "Precision@3: 0.0004\n",
      "F1-score@3:  0.0006\n",
      "Accuracy@3:  0.0004\n",
      "\n",
      "Training with 90% / 10% split:\n",
      "Recall@3:    0.0066\n",
      "Precision@3: 0.0022\n",
      "F1-score@3:  0.0033\n",
      "Accuracy@3:  0.0022\n"
     ]
    }
   ],
   "source": [
    "base_weights_4 = np.array([0.15, 0.25, 0.30, 0.05, 0.10, 0.05, 0.03, 0.02, 0.02, 0.03])\n",
    "X_weighted_4 = set_weights(base_weights_4, preprocessor)\n",
    "resample_cal(splits, n_total, X_weighted_4, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2d7e0052-bb1a-4800-9f11-71acf923d46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split with repeat 5:\n",
      "Accuracy@3:  0.8353\n",
      "Precision@3: 0.8353\n",
      "Recall@3:    0.9721\n",
      "F1-score@3:  0.8985\n",
      "\n",
      "Training with 80% / 20% split with repeat 5:\n",
      "Accuracy@3:  0.8837\n",
      "Precision@3: 0.8837\n",
      "Recall@3:    0.9890\n",
      "F1-score@3:  0.9334\n",
      "\n",
      "Training with 90% / 10% split with repeat 5:\n",
      "Accuracy@3:  0.9249\n",
      "Precision@3: 0.9249\n",
      "Recall@3:    0.9978\n",
      "F1-score@3:  0.9600\n"
     ]
    }
   ],
   "source": [
    "mul_X_weighted_4 = mul_set_weights(base_weights_4, preprocessor, X)\n",
    "mul_resample_cal(splits, n_total=X.shape[0], feature_X=mul_X_weighted_4, label_Y=y, n_repeats=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc7a9d-ac60-459f-83f6-6a4a77028691",
   "metadata": {},
   "source": [
    "#### 5. Test the weight set 5: feature_weights_5 = {\n",
    "\"Language\": 0.15, \r\n",
    "\"Google rating\": 0.15, \r\n",
    "\"Success rate\": 0.15, \r\n",
    "\"Charge\": 0.10,\r\n",
    "\"Visa type\": 0.10, \r\n",
    "\"Experience_years\": 0.10, \r\n",
    "\"Booking preference\": 0.08,\r\n",
    "\"Location\": 0.05, \r\n",
    "\"Availability\": 0.05, \r\n",
    "\"Employment Type\": 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "21c2d315-3718-4838-a2de-f93dc66c0840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split:\n",
      "Recall@3:    0.0015\n",
      "Precision@3: 0.0005\n",
      "F1-score@3:  0.0007\n",
      "Accuracy@3:  0.0005\n",
      "\n",
      "Training with 80% / 20% split:\n",
      "Recall@3:    0.0000\n",
      "Precision@3: 0.0000\n",
      "F1-score@3:  0.0000\n",
      "Accuracy@3:  0.0000\n",
      "\n",
      "Training with 90% / 10% split:\n",
      "Recall@3:    0.0022\n",
      "Precision@3: 0.0007\n",
      "F1-score@3:  0.0011\n",
      "Accuracy@3:  0.0007\n"
     ]
    }
   ],
   "source": [
    "base_weights_5 = np.array([0.15, 0.15, 0.15, 0.10, 0.10, 0.10, 0.08, 0.05, 0.05, 0.07])\n",
    "X_weighted_5 = set_weights(base_weights_5, preprocessor)\n",
    "resample_cal(splits, n_total, X_weighted_5, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "95946a20-be43-4242-8604-91d10035fc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split with repeat 5:\n",
      "Accuracy@3:  0.8353\n",
      "Precision@3: 0.8353\n",
      "Recall@3:    0.9721\n",
      "F1-score@3:  0.8985\n",
      "\n",
      "Training with 80% / 20% split with repeat 5:\n",
      "Accuracy@3:  0.8837\n",
      "Precision@3: 0.8837\n",
      "Recall@3:    0.9890\n",
      "F1-score@3:  0.9334\n",
      "\n",
      "Training with 90% / 10% split with repeat 5:\n",
      "Accuracy@3:  0.9249\n",
      "Precision@3: 0.9249\n",
      "Recall@3:    0.9978\n",
      "F1-score@3:  0.9600\n"
     ]
    }
   ],
   "source": [
    "mul_X_weighted_5 = mul_set_weights(base_weights_5, preprocessor, X)\n",
    "mul_resample_cal(splits, n_total=X.shape[0], feature_X=mul_X_weighted_5, label_Y=y, n_repeats=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf346b-3e15-4052-a5b3-f05824413599",
   "metadata": {},
   "source": [
    "Finally, it shows that the results of setting weights are similar to the results before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db25c6c1-3690-4376-8e44-5c0a7af74d8a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e5106d-132d-4d51-9b70-ced37a3df390",
   "metadata": {},
   "source": [
    "After the experiments above, we can vividly identify that the best result for KNN-CF model is to use the multiple resample method for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3ee70f4a-52fd-4521-8d7e-523610bec4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 70% / 30% split with repeat 5:\n",
      "Accuracy@3:  0.8353\n",
      "Precision@3: 0.8353\n",
      "Recall@3:    0.9721\n",
      "F1-score@3:  0.8985\n",
      "\n",
      "Training with 80% / 20% split with repeat 5:\n",
      "Accuracy@3:  0.8837\n",
      "Precision@3: 0.8837\n",
      "Recall@3:    0.9890\n",
      "F1-score@3:  0.9334\n",
      "\n",
      "Training with 90% / 10% split with repeat 5:\n",
      "Accuracy@3:  0.9249\n",
      "Precision@3: 0.9249\n",
      "Recall@3:    0.9978\n",
      "F1-score@3:  0.9600\n"
     ]
    }
   ],
   "source": [
    "n_repeats = 5\n",
    "mul_resample_cal(splits, n_total, X, y, n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1cec9a-d427-473d-8ea9-49aad531ae0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
